# BERT - Bidirectional Encoder Representations from Transformer

[2018 Paper on Bert](https://arxiv.org/abs/1810.04805)

## What is Bert for?
- Bert is for pre-training Transformer's encoder
- Predict masked word
- Predict next sentence

## Tutorial of Bert

[BERT for pretraining Transformers](https://www.youtube.com/watch?v=EOmd5sUUA_A)
